{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d098e62-f004-4d8b-b3f8-eedb5ffd362b",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "module_path = \"~/github/qhack_2023/\"\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdcdcd4-15b9-45fd-a84a-8733e86698a7",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym.envs.toy_text.frozen_lake import generate_random_map\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from algorithms.q_learning import QLearning\n",
    "from algorithms.qrl_classic import QRLClassic\n",
    "from algorithms.custom_eval_callback import CustomEvalCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2e6eb3-b34e-4c20-8452-248a5b6262a6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "    model,\n",
    "    model_name,\n",
    "    model_parameters: dict,\n",
    "    random_seed: int = 542,\n",
    "    env_map_size: int = 10,\n",
    "    env_non_deterministic: bool = False,\n",
    "    eval_freq: int = 100,\n",
    "    n_eval_episodes: int = 20,\n",
    "    total_timesteps: int = 1_000_000\n",
    "):\n",
    "    np.random.seed(seed=random_seed)\n",
    "    \n",
    "    random_map = generate_random_map(size=env_map_size, p=0.8)\n",
    "    env = gym.make(\"FrozenLake-v1\", desc=random_map, is_slippery=env_non_deterministic)\n",
    "    eval_env = gym.make(\"FrozenLake-v1\", desc=random_map, is_slippery=env_non_deterministic)        \n",
    "        \n",
    "    callback = CustomEvalCallback(\n",
    "        eval_env=eval_env,\n",
    "        eval_freq=eval_freq,\n",
    "        n_eval_episodes=n_eval_episodes,\n",
    "        verbose=0\n",
    "    )\n",
    "        \n",
    "    model = model(\n",
    "        policy = None,\n",
    "        env = env,\n",
    "        **model_parameters,\n",
    "    )\n",
    "    \n",
    "    model.learn(\n",
    "        total_timesteps=total_timesteps,\n",
    "        callback = callback    \n",
    "    )\n",
    "    \n",
    "    learning_curve = callback.learning_curve\n",
    "    eval_freq = callback.eval_freq\n",
    "    \n",
    "    return eval_freq, learning_curve\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cfe3f4-6bc2-4cd8-9278-27ba144129cd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "random_seed = 542\n",
    "np.random.seed(seed=random_seed)\n",
    "random_seeds = [np.random.randint(1000) for _ in range(10)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f25bb3e-864e-4ec0-87dc-45c1ee905aff",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "env_non_deterministic = True\n",
    "env_map_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027e9c4c-60e3-4a0b-9677-f382db0097f3",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "total_timesteps = 100_000  # Total training steps\n",
    "learning_rate = 0.7          # Learning rate\n",
    "\n",
    "# Evaluation parameters\n",
    "n_eval_episodes = 100        # Total number of test episodes\n",
    "eval_freq = 100\n",
    "\n",
    "# Environment parameters\n",
    "max_steps = 200              # Max steps per episode\n",
    "gamma = 0.95                 # Discounting rate\n",
    "\n",
    "# Exploration parameters\n",
    "max_epsilon = 1.0             # Exploration probability at start\n",
    "min_epsilon = 0.01            # Minimum exploration probability \n",
    "decay_rate = 0.01              # Exponential decay rate for exploration prob\n",
    "\n",
    "\n",
    "\n",
    "model_parameters = {\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"gamma\": gamma,\n",
    "    \"max_steps\": max_steps,\n",
    "    \"max_epsilon\": max_epsilon,\n",
    "    \"min_epsilon\": min_epsilon,\n",
    "    \"decay_rate\": decay_rate,\n",
    "    \"verbose\": 0,\n",
    "    \"seed\": None,\n",
    "    \"device\": \"auto\",\n",
    "    \"_init_setup_model\": False,    \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "learning_curves_ql = list()\n",
    "for rs in random_seeds:\n",
    "    _, lc = run_experiment(\n",
    "        model=QLearning,\n",
    "        model_name=\"ql_deterministic\",\n",
    "        model_parameters=model_parameters,\n",
    "        env_non_deterministic=env_non_deterministic,\n",
    "        env_map_size=env_map_size,\n",
    "        eval_freq=eval_freq,\n",
    "        total_timesteps = total_timesteps,\n",
    "        random_seed=rs,\n",
    "    )\n",
    "    learning_curves_ql.append(lc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683b48e9-17f3-40e4-9a56-a941863accf4",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "total_timesteps = 100_000  # Total training steps\n",
    "learning_rate = 0.7          # Learning rate\n",
    "\n",
    "# Evaluation parameters\n",
    "n_eval_episodes = 100        # Total number of test episodes\n",
    "\n",
    "# Environment parameters\n",
    "max_steps = 200               # Max steps per episode\n",
    "gamma = 0.95                 # Discounting rate\n",
    "eval_seed = []               # The evaluation seed of the environment\n",
    "\n",
    "\n",
    "\n",
    "model = QRLClassic\n",
    "\n",
    "model_parameters = {\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"gamma\": gamma,\n",
    "    \"max_steps\": max_steps,\n",
    "    \"verbose\": 0,\n",
    "    \"seed\": None,\n",
    "    \"device\": \"auto\",\n",
    "    \"_init_setup_model\": False,    \n",
    "}\n",
    "\n",
    "\n",
    "learning_curves_qrl = list()\n",
    "for rs in random_seeds:\n",
    "    _, lc = run_experiment(\n",
    "        model=QRLClassic,\n",
    "        model_name=\"qrl\",\n",
    "        model_parameters=model_parameters,\n",
    "        env_non_deterministic=env_non_deterministic,\n",
    "        env_map_size=env_map_size,\n",
    "        eval_freq=eval_freq,\n",
    "        total_timesteps = total_timesteps,\n",
    "        random_seed=rs,\n",
    "    )\n",
    "    learning_curves_qrl.append(lc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05b06b6-7761-4493-acef-56c92dea32e8",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=2, shared_yaxes=True, subplot_titles=(\"Q-learning\", \"QRL\"))\n",
    "\n",
    "\n",
    "cutoff = 100\n",
    "for i, lc in enumerate(learning_curves_ql):\n",
    "    lc = lc[:cutoff]\n",
    "    mean_reward = [c[0] for c in lc]\n",
    "    x = [e*eval_freq for e in range(len(mean_reward))]\n",
    "        \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x,\n",
    "            y=mean_reward,\n",
    "            mode=\"lines\",\n",
    "            name=f\"ql_mean_reward_{i}\",\n",
    "        ),\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )   \n",
    "    \n",
    "for i, lc in enumerate(learning_curves_qrl):\n",
    "    lc = lc[:cutoff]    \n",
    "    mean_reward = [c[0] for c in lc]\n",
    "    x = [e*eval_freq for e in range(len(mean_reward))]\n",
    "        \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x,\n",
    "            y=mean_reward,\n",
    "            mode=\"lines\",\n",
    "            name=f\"qrl_mean_reward_{i}\",\n",
    "        ),\n",
    "        row=1,\n",
    "        col=2,\n",
    "    )   \n",
    "    \n",
    "fig.update_layout(width=1200, height=600, showlegend=True, title_text=f\"QL vs QRL learning curves (map size {env_map_size} random {env_non_deterministic})\")\n",
    "fig.show()    \n",
    "plot_name = f\"../images/ql_vs_qrl_size_{env_map_size}_random_{env_non_deterministic}\"\n",
    "fig.write_html(f\"{plot_name}.html\")\n",
    "fig.write_image(f\"{plot_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445fdb65-273f-4899-99ca-54398e754994",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}